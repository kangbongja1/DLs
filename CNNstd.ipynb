import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

print(tf.__version__)

print(keras.__version__)
2.7.0
2.7.0
image = tf.constant([[[[1],[2],[3]],
                    [[4],[5],[6]],
                    [[7],[8],[9]]]], dtype=np.float32)
print(image.shape)
plt.imshow(image.numpy().reshape(3,3), cmap='Greys')
plt.show()

#하단 1, 3, 3,1
# batch, h , w , c 순서
(1, 3, 3, 1)

#(1,1
# 1,1) 필터로 계산시
# (12, 16
# 24, 28) 나옴
print("image.shape", image.shape)
weight = np.array([[[[1.]],[[1.]]],
                    [[[1.]],[[1.]]]]) #필터
print("weight.shape", weight.shape)
weight_init = tf.constant_initializer(weight)
conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='VALID',
kernel_initializer=weight_init)(image)
print("conv2d.shape", conv2d.shape)
print(conv2d.numpy().reshape(2,2))
plt.imshow(conv2d.numpy().reshape(2,2), cmap='gray')
plt.show()

#필터 쉐입 (h, w, ch, 개수)
image.shape (1, 3, 3, 1)
weight.shape (2, 2, 1, 1)
conv2d.shape (1, 2, 2, 1)
[[12. 16.]
 [24. 28.]]

print("image.shape", image.shape)
weight = np.array([[[[1.]],[[1.]]],
                    [[[1.]],[[1.]]]]) #필터
print("weight.shape", weight.shape)
weight_init = tf.constant_initializer(weight)
conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='SAME',
kernel_initializer=weight_init)(image)
print("conv2d.shape", conv2d.shape)
print(conv2d.numpy().reshape(3,3))
plt.imshow(conv2d.numpy().reshape(3,3), cmap='gray')
plt.show()

#padding SAME, reshape 3x3 
image.shape (1, 3, 3, 1)
weight.shape (2, 2, 1, 1)
conv2d.shape (1, 3, 3, 1)
[[12. 16.  9.]
 [24. 28. 15.]
 [15. 17.  9.]]

#필터 3개쓰는 경우 (h=2 , w=2 , ch=1 , 개수 3 )

print("image.shape", image.shape)
weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],
                [[[1.,10.,-1.]],[[1.,10.,-1.]]]])## 쉐입 : 2x2 필터에
                                                # 1 1 / 1 1 필터하나 
                                                #10,10 /10 ,10 필터하나 
                                                #-1,-1 / -1,-1 필터하나 
print("weight.shape", weight.shape)
weight_init = tf.constant_initializer(weight)
conv2d = keras.layers.Conv2D(filters=3, kernel_size=2, padding='SAME',
                                    kernel_initializer=weight_init)(image)
print("conv2d.shape", conv2d.shape)
feature_maps = np.swapaxes(conv2d, 0, 3)
for i, feature_map in enumerate(feature_maps):
    print(feature_map.reshape(3,3))
    plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')
plt.show()
image.shape (1, 3, 3, 1)
weight.shape (2, 2, 1, 3)
conv2d.shape (1, 3, 3, 3)
[[12. 16.  9.]
 [24. 28. 15.]
 [15. 17.  9.]]
[[120. 160.  90.]
 [240. 280. 150.]
 [150. 170.  90.]]
[[-12. -16.  -9.]
 [-24. -28. -15.]
 [-15. -17.  -9.]]

###########
######pool_size 풀랑 사이즈 , 기본값 2x2 
####strinde, padding, data_format = convolution이랑 동일
image = tf.constant([[[[4],[3]],
    [[2],[1]]]], dtype=np.float32)
pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1,
        padding='VALID')(image) ## 패딩을 안함
print(pool.shape)
print(pool.numpy())
(1, 1, 1, 1)
[[[[4.]]]]
image = tf.constant([[[[4],[3]],
    [[2],[1]]]], dtype=np.float32)
pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1,
    padding='SAME')(image) ####패딩함
print(pool.shape)
print(pool.numpy())
(1, 2, 2, 1)
[[[[4.]
   [3.]]

  [[2.]
   [1.]]]]
########
mnist = keras.datasets.mnist
class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.astype(np.float32) / 255.
test_images = test_images.astype(np.float32) / 255.

img = train_images[0]
plt.imshow(img, cmap='gray')
plt.show()
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 1s 0us/step
11501568/11490434 [==============================] - 1s 0us/step

#Convolution Layer – Output Feature Maps
img = img.reshape(-1,28,28,1) #img > convolution 연산에 input = 4차원으로 변환 
img = tf.convert_to_tensor(img)
weight_init = keras.initializers.RandomNormal(stddev=0.01)
conv2d = keras.layers.Conv2D(filters=5, kernel_size=3, strides=(2, 2), # 3x3 필터 5개 
    padding='SAME', kernel_initializer=weight_init)(img)
print(conv2d.shape)
feature_maps = np.swapaxes(conv2d, 0, 3)
for i, feature_map in enumerate(feature_maps):
    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(14,14),
cmap='gray')
plt.show()
(1, 14, 14, 5)

#Pooling Layer – Output Feature Maps
pool = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), # 2,2 필터 
    padding='SAME')(conv2d)
print(pool.shape)
feature_maps = np.swapaxes(pool, 0, 3)
for i, feature_map in enumerate(feature_maps):
    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(7, 7),
cmap='gray')
plt.show()
(1, 7, 7, 5)

# Fully Connected : feature들을 모아서 classification
# 풀링한 결과 : 입체 > 벡터형태, 전부연결 perceptrone > 출력값 softmax 통과 
###############11-1 CNN with MNIST Dataset using tf.keras Sequential APIs
#NN Implementation Flow in TensorFlow
#1. Set hyper parameters – learning rate, training epochs, batch size, etc.
##
#2. Make a data pipelining – use tf.data
## data pipelining // data : loaded > batch size 만큼 가져와서 뒤에 공급 
##
#3. Build a neural network model – use tf.keras sequential APIs
#4. Define a loss function – cross entropy
#5. Calculate a gradient – use tf.GradientTape
##
#6. Select an optimizer – Adam optimizer
## 계산된 gradient를 사용해서 weight 업데이트
##
#7. Define a metric for model’s performance – accuracy
#8. (optional) Make a checkpoint for saving
#9. Train and Validate a neural network mode
# CNN 구성
# MNIST 28x28 이미지 / 3x3 convl / 2x2 mx pl / 3x3 convl / 2x2 mx pl / 3x3 convl / 2x2 mx p / fully cnnted
# convl stride 1 padding SAME # mx pl stride 2 pad SAME
# 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
import os
learning_rate = 0.001
training_epochs = 15
batch_size = 100


##chckpnt
cur_dir = os.getcwd()
ckpt_dir_name = 'checkpoints'
model_dir_name = 'minst_cnn_seq'

checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)
os.makedirs(checkpoint_dir, exist_ok=True)

checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)
#2. Make a Data Pipelining
mnist = keras.datasets.mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data() # 3차원인걸 >

train_images = train_images.astype(np.float32) / 255.
test_images = test_images.astype(np.float32) / 255.
train_images = np.expand_dims(train_images, axis=-1) # 4차원으로
test_images = np.expand_dims(test_images, axis=-1) # 

train_labels = to_categorical(train_labels, 10)
test_labels = to_categorical(test_labels, 10)

#데이터 배치사이즈만큼 slice > 공급
train_dataset = tf.data.Dataset.from_tensor_slices((train_images,
    train_labels)).shuffle(buffer_size=100000).batch(batch_size)
test_dataset = tf.data.Dataset.from_tensor_slices((test_images,
    test_labels)).batch(batch_size)
#3. Build a Neural Network Model– Sequential API
def create_model():
    model = keras.Sequential()
    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, 
                                  padding='SAME', input_shape=(28, 28, 1)))
    model.add(keras.layers.MaxPool2D(padding='SAME'))
    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, 
                                  padding='SAME'))
    model.add(keras.layers.MaxPool2D(padding='SAME'))
    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu,
                                  padding='SAME'))
    model.add(keras.layers.MaxPool2D(padding='SAME'))
    model.add(keras.layers.Flatten())
    model.add(keras.layers.Dense(256, activation=tf.nn.relu))
    model.add(keras.layers.Dropout(0.4))
    model.add(keras.layers.Dense(10))
    return model
model = create_model()
model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_8 (Conv2D)           (None, 28, 28, 32)        320       
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 14, 14, 32)       0         
 2D)                                                             
                                                                 
 conv2d_9 (Conv2D)           (None, 14, 14, 64)        18496     
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 conv2d_10 (Conv2D)          (None, 7, 7, 128)         73856     
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 dense (Dense)               (None, 256)               524544    
                                                                 
 dropout (Dropout)           (None, 256)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                2570      
                                                                 
=================================================================
Total params: 619,786
Trainable params: 619,786
Non-trainable params: 0
_________________________________________________________________
# Define a Loss Function
# Calculate a Gradient
def loss_fn(model, images, labels):
    logits = model(images, training=True)
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(
        logits=logits, labels=labels))
    return loss

def grad(model, images, labels):
    with tf.GradientTape() as tape:
        loss = loss_fn(model, images, labels)
    return tape.gradient(loss, model.variables)
# Select an Optimizer
# Define a Metric for Model’s Performance
# Make a Checkpoint for Saving

optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)

def evaluate(model, images, labels):
    logits = model(images, training=False)
    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy

checkpoint = tf.train.Checkpoint(cnn=model)

#############################################################???????????
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_23016/3865002132.py in <module>
      2 # Define a Metric for Model’s Performance
      3 # Make a Checkpoint for Saving
----> 4 optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
      5 
      6 def evaluate(model, images, labels):

AttributeError: module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'
# Train and Validate a Neural Network Model
for epoch in range(training_epochs):
    avg_loss = 0.
    avg_train_acc = 0.
    avg_test_acc = 0.
    train_step = 0
    test_step = 0
for images, labels in train_dataset:
    grads = grad(model, images, labels)
    optimizer.apply_gradients(zip(grads, model.variables))
    loss = loss_fn(model, images, labels)
    acc = evaluate(model, images, labels)
    avg_loss = avg_loss + loss
    avg_train_acc = avg_train_acc + acc
    train_step += 1
avg_loss = avg_loss / train_step
avg_train_acc = avg_train_acc / train_step
# Train and Validate a Neural Network Model
for images, labels in test_dataset:
        acc = evaluate(model, images, labels)
        avg_test_acc = avg_test_acc + acc
        test_step += 1
    avg_test_acc = avg_test_acc / test_step

print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss),
      'train accuracy = ', '{:.4f}'.format(avg_train_acc),
      'test accuracy = ', '{:.4f}'.format(avg_test_acc))
checkpoint.save(file_prefix=checkpoint_prefix)
